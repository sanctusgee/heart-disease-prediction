{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Predicting Heart Disease\n",
    "In this example, we will build and evaluate machine learning models to predict heart disease based on diagnostic measurements. We will use the Heart Disease UCI dataset from the UCI Machine Learning Repository."
   ],
   "id": "71eb92e8e1834a6b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "##### Objective:\n",
    "Predict whether a patient has heart disease based on diagnostic measurements.\n",
    "##### Dataset:\n",
    "Heart Disease UCI dataset from the UCI Machine Learning Repository."
   ],
   "id": "d7faebc33cd6cf4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Data Description**\n",
    "The dataset contains various diagnostic measurements for patients, as well as a target variable indicating the presence or absence of heart disease.\n",
    "\n",
    "##### Features: #####\n",
    "\n",
    "    1. age: age in years\n",
    "    2. sex: Sex (1 = male; 0 = female).\n",
    "    3. cp: Chest pain type (0-3).\n",
    "    4. trestbps: Resting blood pressure (in mm Hg on admission to the hospital).\n",
    "    5. chol: Serum cholesterol in mg/dl.\n",
    "    6. fbs: Fasting blood sugar > 120 mg/dl (1 = true; 0 = false).\n",
    "    7. restecg: Resting electrocardiographic results (0-2).\n",
    "    8. thalach: Maximum heart rate achieved.\n",
    "    9. exang: Exercise-induced angina (1 = yes; 0 = no).\n",
    "    10. oldpeak: ST depression induced by exercise relative to rest.\n",
    "    11. slope: The slope of the peak exercise ST segment (0-2).\n",
    "    12. ca: Number of major vessels (0-3) colored by fluoroscopy.\n",
    "    13. thal: Thalassemia (1 = normal; 2 = fixed defect; 3 = reversible defect).\n",
    "    14. target: Diagnosis of heart disease (1 = presence; 0 = absence)."
   ],
   "id": "2dd7eceb3fc26596"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('processed.cleveland.data', header=None)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head())\n",
    "\n",
    "# Assuming the location column is the last column (adjust the index if necessary)\n",
    "# Filter the dataset to include only Cleveland data\n",
    "# Note: If the dataset does not have a location column, this step can be skipped\n",
    "# cleveland_data = data[data.iloc[:, -1] == 'cleveland']\n",
    "\n",
    "# For this example, we assume the dataset is already filtered to include only Cleveland data\n",
    "cleveland_data = data\n",
    "\n",
    "# Display the first few rows of the filtered dataset\n",
    "print(cleveland_data.head())\n",
    "\n",
    "# Define column names for the dataset\n",
    "column_names = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
    "cleveland_data.columns = column_names"
   ],
   "id": "76d84086f76ea6c2"
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "Exploratory Data Analysis",
   "id": "210e3a76ac04bf10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# Check for missing values\n",
    "print(cleveland_data.isnull().sum())\n",
    "\n",
    "# Summary statistics\n",
    "print(cleveland_data.describe())\n",
    "\n",
    "# Correlation matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(cleveland_data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "# Pairplot\n",
    "sns.pairplot(cleveland_data)\n",
    "plt.show()"
   ],
   "id": "588a2b65b81d4743"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model Building and Training",
   "id": "69a469eed42297a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = cleveland_data.drop('target', axis=1)\n",
    "y = cleveland_data['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Train a Decision Tree model with GridSearchCV\n",
    "param_grid_dt = {'max_depth': [3, 5, 7, 10], 'min_samples_split': [2, 5, 10]}\n",
    "grid_dt = GridSearchCV(DecisionTreeClassifier(), param_grid_dt, cv=3)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "dt = grid_dt.best_estimator_\n",
    "\n",
    "# Train a Random Forest model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Train a Gradient Boosting model\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(X_train, y_train)\n",
    "\n",
    "# Train a Bagging Classifier\n",
    "bagging = BaggingClassifier()\n",
    "bagging.fit(X_train, y_train)\n",
    "\n",
    "# Train a Support Vector Classifier with GridSearchCV\n",
    "param_grid_svc = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01]}\n",
    "grid_svc = GridSearchCV(SVC(), param_grid_svc, cv=3)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "svc = grid_svc.best_estimator_\n",
    "\n",
    "# Train a K-Nearest Neighbors model\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ],
   "id": "2778072d0b2948cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Results and Evaulations",
   "id": "63293a814be0d707"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluate the models\n",
    "models = {\n",
    "    'Logistic Regression': lr,\n",
    "    'Decision Tree': dt,\n",
    "    'Random Forest': rf,\n",
    "    'Gradient Boosting': gb,\n",
    "    'Bagging': bagging,\n",
    "    'Support Vector Classifier': svc,\n",
    "    'K-Nearest Neighbors': knn\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f'{name} - Accuracy: {accuracy:.2f}, Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}')"
   ],
   "id": "cd9a8c4d5041a785"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Display feature importances for the Random Forest model\n",
    "feature_importances = pd.DataFrame({'feature': X.columns, 'importance': rf.feature_importances_})\n",
    "feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
    "\n",
    "# Heat map for Decision Tree\n",
    "results_dt = pd.DataFrame(grid_dt.cv_results_)\n",
    "scores_dt = results_dt.pivot(\"param_max_depth\", \"param_min_samples_split\", \"mean_test_score\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(scores_dt, annot=True, cmap='viridis')\n",
    "plt.title('Decision Tree Grid Search Scores')\n",
    "plt.show()\n",
    "\n",
    "# Heat map for Support Vector Classifier\n",
    "results_svc = pd.DataFrame(grid_svc.cv_results_)\n",
    "scores_svc = results_svc.pivot(\"param_C\", \"param_gamma\", \"mean_test_score\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(scores_svc, annot=True, cmap='viridis')\n",
    "plt.title('Support Vector Classifier Grid Search Scores')\n",
    "plt.show()"
   ],
   "id": "8735760f93e4b539"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
